{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10595384,"sourceType":"datasetVersion","datasetId":6557968}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:14:38.339763Z","iopub.execute_input":"2025-03-10T17:14:38.340186Z","iopub.status.idle":"2025-03-10T17:14:38.347566Z","shell.execute_reply.started":"2025-03-10T17:14:38.340155Z","shell.execute_reply":"2025-03-10T17:14:38.346506Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/house-pricing-dataset/house_prices.csv\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# Load the dataset\nfile_path = \"/kaggle/input/house-pricing-dataset/house_prices.csv\"\ndf = pd.read_csv(file_path)\n\n# Display basic info to confirm successful loading\ndf.info(), df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:14:38.349080Z","iopub.execute_input":"2025-03-10T17:14:38.349478Z","iopub.status.idle":"2025-03-10T17:14:38.433773Z","shell.execute_reply.started":"2025-03-10T17:14:38.349436Z","shell.execute_reply":"2025-03-10T17:14:38.432748Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 21613 entries, 0 to 21612\nData columns (total 21 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   id             21613 non-null  int64  \n 1   date           21613 non-null  object \n 2   price          21613 non-null  float64\n 3   bedrooms       21613 non-null  int64  \n 4   bathrooms      21613 non-null  float64\n 5   sqft_living    21613 non-null  int64  \n 6   sqft_lot       21613 non-null  int64  \n 7   floors         21613 non-null  float64\n 8   waterfront     21613 non-null  object \n 9   view           21613 non-null  int64  \n 10  condition      21613 non-null  object \n 11  grade          21613 non-null  int64  \n 12  sqft_above     21613 non-null  int64  \n 13  sqft_basement  21613 non-null  int64  \n 14  yr_built       21613 non-null  int64  \n 15  yr_renovated   21613 non-null  int64  \n 16  zipcode        21613 non-null  int64  \n 17  lat            21613 non-null  float64\n 18  long           21613 non-null  float64\n 19  sqft_living15  21613 non-null  int64  \n 20  sqft_lot15     21613 non-null  int64  \ndtypes: float64(5), int64(13), object(3)\nmemory usage: 3.5+ MB\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"(None,\n            id             date     price  bedrooms  bathrooms  sqft_living  \\\n 0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n 1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n 2  5631500400  20150225T000000  180000.0         2       1.00          770   \n 3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n 4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n \n    sqft_lot  floors waterfront  view  ... grade  sqft_above  sqft_basement  \\\n 0      5650     1.0          N     0  ...     7        1180              0   \n 1      7242     2.0          N     0  ...     7        2170            400   \n 2     10000     1.0          N     0  ...     6         770              0   \n 3      5000     1.0          N     0  ...     7        1050            910   \n 4      8080     1.0          N     0  ...     8        1680              0   \n \n    yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n 0      1955             0    98178  47.5112 -122.257           1340   \n 1      1951          1991    98125  47.7210 -122.319           1690   \n 2      1933             0    98028  47.7379 -122.233           2720   \n 3      1965             0    98136  47.5208 -122.393           1360   \n 4      1987             0    98074  47.6168 -122.045           1800   \n \n    sqft_lot15  \n 0        5650  \n 1        7639  \n 2        8062  \n 3        5000  \n 4        7503  \n \n [5 rows x 21 columns])"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"# Drop unnecessary columns\ndf_cleaned = df.drop(columns=[\"id\", \"date\"])\n\n# Encode categorical variables\ndf_cleaned[\"waterfront\"] = df_cleaned[\"waterfront\"].map({\"Y\": 1, \"N\": 0})\ndf_cleaned[\"condition\"] = LabelEncoder().fit_transform(df_cleaned[\"condition\"])\n\n# Define features and target variable\nX = df_cleaned.drop(columns=[\"price\"])\ny = df_cleaned[\"price\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:14:38.797256Z","iopub.execute_input":"2025-03-10T17:14:38.797582Z","iopub.status.idle":"2025-03-10T17:14:38.814028Z","shell.execute_reply.started":"2025-03-10T17:14:38.797559Z","shell.execute_reply":"2025-03-10T17:14:38.812752Z"}},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":"**Pre-Processing**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\n\n# Drop unnecessary columns\ndf_cleaned = df.drop(columns=[\"id\", \"date\"])\n\n# Encode categorical variables\ndf_cleaned[\"waterfront\"] = df_cleaned[\"waterfront\"].map({\"Y\": 1, \"N\": 0})\ndf_cleaned[\"condition\"] = LabelEncoder().fit_transform(df_cleaned[\"condition\"])\n\n# Define features and target variable\nX = df_cleaned.drop(columns=[\"price\"])\ny = df_cleaned[\"price\"]\n\n# Split into training and test sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Add constant term for statsmodels\nX_train_sm = sm.add_constant(X_train)\nX_test_sm = sm.add_constant(X_test)\n\n# Fit model with all variables (baseline model)\nmodel_all = sm.OLS(y_train, X_train_sm).fit()\n\n# Store results\nmodel_results = {\"All Variables\": model_all}\n\n# Show summary of the baseline model\nmodel_all.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:14:38.815399Z","iopub.execute_input":"2025-03-10T17:14:38.815731Z","iopub.status.idle":"2025-03-10T17:14:38.895465Z","shell.execute_reply.started":"2025-03-10T17:14:38.815703Z","shell.execute_reply":"2025-03-10T17:14:38.894293Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                  price   R-squared:                       0.699\nModel:                            OLS   Adj. R-squared:                  0.699\nMethod:                 Least Squares   F-statistic:                     2363.\nDate:                Mon, 10 Mar 2025   Prob (F-statistic):               0.00\nTime:                        17:14:38   Log-Likelihood:            -2.3542e+05\nNo. Observations:               17290   AIC:                         4.709e+05\nDf Residuals:                   17272   BIC:                         4.710e+05\nDf Model:                          17                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst          6.219e+06   3.24e+06      1.917      0.055    -1.4e+05    1.26e+07\nbedrooms      -3.421e+04   2082.322    -16.428      0.000   -3.83e+04   -3.01e+04\nbathrooms      4.439e+04   3607.091     12.306      0.000    3.73e+04    5.15e+04\nsqft_living     108.9036      2.530     43.042      0.000     103.944     113.863\nsqft_lot          0.0835      0.058      1.445      0.148      -0.030       0.197\nfloors         7148.8493   3958.506      1.806      0.071    -610.224    1.49e+04\nwaterfront     5.615e+05   1.95e+04     28.786      0.000    5.23e+05       6e+05\nview           5.359e+04   2358.736     22.718      0.000     4.9e+04    5.82e+04\ncondition      1.367e+04   1357.528     10.070      0.000     1.1e+04    1.63e+04\ngrade          9.512e+04   2371.099     40.116      0.000    9.05e+04    9.98e+04\nsqft_above       69.9982      2.486     28.162      0.000      65.126      74.870\nsqft_basement    38.8995      2.938     13.238      0.000      33.140      44.659\nyr_built      -2642.7084     80.986    -32.632      0.000   -2801.449   -2483.968\nyr_renovated     21.4308      4.071      5.264      0.000      13.451      29.411\nzipcode        -548.1478     36.460    -15.034      0.000    -619.614    -476.682\nlat            5.969e+05   1.19e+04     50.305      0.000    5.74e+05     6.2e+05\nlong          -1.944e+05   1.46e+04    -13.312      0.000   -2.23e+05   -1.66e+05\nsqft_living15    20.9021      3.809      5.488      0.000      13.436      28.368\nsqft_lot15       -0.3246      0.082     -3.968      0.000      -0.485      -0.164\n==============================================================================\nOmnibus:                    14975.304   Durbin-Watson:                   1.994\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          1712544.182\nSkew:                           3.632   Prob(JB):                         0.00\nKurtosis:                      51.212   Cond. No.                     9.57e+16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 1.91e-20. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.699</td>  \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.699</td>  \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2363.</td>  \n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 10 Mar 2025</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n</tr>\n<tr>\n  <th>Time:</th>                 <td>17:14:38</td>     <th>  Log-Likelihood:    </th> <td>-2.3542e+05</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td> 17290</td>      <th>  AIC:               </th>  <td>4.709e+05</td> \n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td> 17272</td>      <th>  BIC:               </th>  <td>4.710e+05</td> \n</tr>\n<tr>\n  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>      <td> </td>     \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>         <td> 6.219e+06</td> <td> 3.24e+06</td> <td>    1.917</td> <td> 0.055</td> <td> -1.4e+05</td> <td> 1.26e+07</td>\n</tr>\n<tr>\n  <th>bedrooms</th>      <td>-3.421e+04</td> <td> 2082.322</td> <td>  -16.428</td> <td> 0.000</td> <td>-3.83e+04</td> <td>-3.01e+04</td>\n</tr>\n<tr>\n  <th>bathrooms</th>     <td> 4.439e+04</td> <td> 3607.091</td> <td>   12.306</td> <td> 0.000</td> <td> 3.73e+04</td> <td> 5.15e+04</td>\n</tr>\n<tr>\n  <th>sqft_living</th>   <td>  108.9036</td> <td>    2.530</td> <td>   43.042</td> <td> 0.000</td> <td>  103.944</td> <td>  113.863</td>\n</tr>\n<tr>\n  <th>sqft_lot</th>      <td>    0.0835</td> <td>    0.058</td> <td>    1.445</td> <td> 0.148</td> <td>   -0.030</td> <td>    0.197</td>\n</tr>\n<tr>\n  <th>floors</th>        <td> 7148.8493</td> <td> 3958.506</td> <td>    1.806</td> <td> 0.071</td> <td> -610.224</td> <td> 1.49e+04</td>\n</tr>\n<tr>\n  <th>waterfront</th>    <td> 5.615e+05</td> <td> 1.95e+04</td> <td>   28.786</td> <td> 0.000</td> <td> 5.23e+05</td> <td>    6e+05</td>\n</tr>\n<tr>\n  <th>view</th>          <td> 5.359e+04</td> <td> 2358.736</td> <td>   22.718</td> <td> 0.000</td> <td>  4.9e+04</td> <td> 5.82e+04</td>\n</tr>\n<tr>\n  <th>condition</th>     <td> 1.367e+04</td> <td> 1357.528</td> <td>   10.070</td> <td> 0.000</td> <td>  1.1e+04</td> <td> 1.63e+04</td>\n</tr>\n<tr>\n  <th>grade</th>         <td> 9.512e+04</td> <td> 2371.099</td> <td>   40.116</td> <td> 0.000</td> <td> 9.05e+04</td> <td> 9.98e+04</td>\n</tr>\n<tr>\n  <th>sqft_above</th>    <td>   69.9982</td> <td>    2.486</td> <td>   28.162</td> <td> 0.000</td> <td>   65.126</td> <td>   74.870</td>\n</tr>\n<tr>\n  <th>sqft_basement</th> <td>   38.8995</td> <td>    2.938</td> <td>   13.238</td> <td> 0.000</td> <td>   33.140</td> <td>   44.659</td>\n</tr>\n<tr>\n  <th>yr_built</th>      <td>-2642.7084</td> <td>   80.986</td> <td>  -32.632</td> <td> 0.000</td> <td>-2801.449</td> <td>-2483.968</td>\n</tr>\n<tr>\n  <th>yr_renovated</th>  <td>   21.4308</td> <td>    4.071</td> <td>    5.264</td> <td> 0.000</td> <td>   13.451</td> <td>   29.411</td>\n</tr>\n<tr>\n  <th>zipcode</th>       <td> -548.1478</td> <td>   36.460</td> <td>  -15.034</td> <td> 0.000</td> <td> -619.614</td> <td> -476.682</td>\n</tr>\n<tr>\n  <th>lat</th>           <td> 5.969e+05</td> <td> 1.19e+04</td> <td>   50.305</td> <td> 0.000</td> <td> 5.74e+05</td> <td>  6.2e+05</td>\n</tr>\n<tr>\n  <th>long</th>          <td>-1.944e+05</td> <td> 1.46e+04</td> <td>  -13.312</td> <td> 0.000</td> <td>-2.23e+05</td> <td>-1.66e+05</td>\n</tr>\n<tr>\n  <th>sqft_living15</th> <td>   20.9021</td> <td>    3.809</td> <td>    5.488</td> <td> 0.000</td> <td>   13.436</td> <td>   28.368</td>\n</tr>\n<tr>\n  <th>sqft_lot15</th>    <td>   -0.3246</td> <td>    0.082</td> <td>   -3.968</td> <td> 0.000</td> <td>   -0.485</td> <td>   -0.164</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>14975.304</td> <th>  Durbin-Watson:     </th>  <td>   1.994</td>  \n</tr>\n<tr>\n  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1712544.182</td>\n</tr>\n<tr>\n  <th>Skew:</th>           <td> 3.632</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n</tr>\n<tr>\n  <th>Kurtosis:</th>       <td>51.212</td>   <th>  Cond. No.          </th>  <td>9.57e+16</td>  \n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.91e-20. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular.","text/latex":"\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &      price       & \\textbf{  R-squared:         } &      0.699   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.699   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      2363.   \\\\\n\\textbf{Date:}             & Mon, 10 Mar 2025 & \\textbf{  Prob (F-statistic):} &      0.00    \\\\\n\\textbf{Time:}             &     17:14:38     & \\textbf{  Log-Likelihood:    } & -2.3542e+05  \\\\\n\\textbf{No. Observations:} &       17290      & \\textbf{  AIC:               } &  4.709e+05   \\\\\n\\textbf{Df Residuals:}     &       17272      & \\textbf{  BIC:               } &  4.710e+05   \\\\\n\\textbf{Df Model:}         &          17      & \\textbf{                     } &              \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &              \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                        & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}          &    6.219e+06  &     3.24e+06     &     1.917  &         0.055        &     -1.4e+05    &     1.26e+07     \\\\\n\\textbf{bedrooms}       &   -3.421e+04  &     2082.322     &   -16.428  &         0.000        &    -3.83e+04    &    -3.01e+04     \\\\\n\\textbf{bathrooms}      &    4.439e+04  &     3607.091     &    12.306  &         0.000        &     3.73e+04    &     5.15e+04     \\\\\n\\textbf{sqft\\_living}   &     108.9036  &        2.530     &    43.042  &         0.000        &      103.944    &      113.863     \\\\\n\\textbf{sqft\\_lot}      &       0.0835  &        0.058     &     1.445  &         0.148        &       -0.030    &        0.197     \\\\\n\\textbf{floors}         &    7148.8493  &     3958.506     &     1.806  &         0.071        &     -610.224    &     1.49e+04     \\\\\n\\textbf{waterfront}     &    5.615e+05  &     1.95e+04     &    28.786  &         0.000        &     5.23e+05    &        6e+05     \\\\\n\\textbf{view}           &    5.359e+04  &     2358.736     &    22.718  &         0.000        &      4.9e+04    &     5.82e+04     \\\\\n\\textbf{condition}      &    1.367e+04  &     1357.528     &    10.070  &         0.000        &      1.1e+04    &     1.63e+04     \\\\\n\\textbf{grade}          &    9.512e+04  &     2371.099     &    40.116  &         0.000        &     9.05e+04    &     9.98e+04     \\\\\n\\textbf{sqft\\_above}    &      69.9982  &        2.486     &    28.162  &         0.000        &       65.126    &       74.870     \\\\\n\\textbf{sqft\\_basement} &      38.8995  &        2.938     &    13.238  &         0.000        &       33.140    &       44.659     \\\\\n\\textbf{yr\\_built}      &   -2642.7084  &       80.986     &   -32.632  &         0.000        &    -2801.449    &    -2483.968     \\\\\n\\textbf{yr\\_renovated}  &      21.4308  &        4.071     &     5.264  &         0.000        &       13.451    &       29.411     \\\\\n\\textbf{zipcode}        &    -548.1478  &       36.460     &   -15.034  &         0.000        &     -619.614    &     -476.682     \\\\\n\\textbf{lat}            &    5.969e+05  &     1.19e+04     &    50.305  &         0.000        &     5.74e+05    &      6.2e+05     \\\\\n\\textbf{long}           &   -1.944e+05  &     1.46e+04     &   -13.312  &         0.000        &    -2.23e+05    &    -1.66e+05     \\\\\n\\textbf{sqft\\_living15} &      20.9021  &        3.809     &     5.488  &         0.000        &       13.436    &       28.368     \\\\\n\\textbf{sqft\\_lot15}    &      -0.3246  &        0.082     &    -3.968  &         0.000        &       -0.485    &       -0.164     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 14975.304 & \\textbf{  Durbin-Watson:     } &      1.994   \\\\\n\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 1712544.182  \\\\\n\\textbf{Skew:}          &    3.632  & \\textbf{  Prob(JB):          } &       0.00   \\\\\n\\textbf{Kurtosis:}      &   51.212  & \\textbf{  Cond. No.          } &   9.57e+16   \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The smallest eigenvalue is 1.91e-20. This might indicate that there are \\newline\n strong multicollinearity problems or that the design matrix is singular."},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\n\n# Drop unnecessary columns\ndf_cleaned = df.drop(columns=[\"id\", \"date\"])\n\n# Encode categorical variables\ndf_cleaned[\"waterfront\"] = df_cleaned[\"waterfront\"].map({\"Y\": 1, \"N\": 0})\ndf_cleaned[\"condition\"] = LabelEncoder().fit_transform(df_cleaned[\"condition\"])\n\n# Define features and target variable\nX = df_cleaned.drop(columns=[\"price\"])\ny = df_cleaned[\"price\"]\n\n# Split into training and test sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Add constant term for statsmodels\nX_train_sm = sm.add_constant(X_train)\nX_test_sm = sm.add_constant(X_test)\n\n# Fit model with all variables (baseline model)\nmodel_all = sm.OLS(y_train, X_train_sm).fit()\n\n# Store results\nmodel_results = {\"All Variables\": model_all}\n\n# Show summary of the baseline model\nmodel_all.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:14:38.897267Z","iopub.execute_input":"2025-03-10T17:14:38.897569Z","iopub.status.idle":"2025-03-10T17:14:38.975089Z","shell.execute_reply.started":"2025-03-10T17:14:38.897543Z","shell.execute_reply":"2025-03-10T17:14:38.973993Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                  price   R-squared:                       0.699\nModel:                            OLS   Adj. R-squared:                  0.699\nMethod:                 Least Squares   F-statistic:                     2363.\nDate:                Mon, 10 Mar 2025   Prob (F-statistic):               0.00\nTime:                        17:14:38   Log-Likelihood:            -2.3542e+05\nNo. Observations:               17290   AIC:                         4.709e+05\nDf Residuals:                   17272   BIC:                         4.710e+05\nDf Model:                          17                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst          6.219e+06   3.24e+06      1.917      0.055    -1.4e+05    1.26e+07\nbedrooms      -3.421e+04   2082.322    -16.428      0.000   -3.83e+04   -3.01e+04\nbathrooms      4.439e+04   3607.091     12.306      0.000    3.73e+04    5.15e+04\nsqft_living     108.9036      2.530     43.042      0.000     103.944     113.863\nsqft_lot          0.0835      0.058      1.445      0.148      -0.030       0.197\nfloors         7148.8493   3958.506      1.806      0.071    -610.224    1.49e+04\nwaterfront     5.615e+05   1.95e+04     28.786      0.000    5.23e+05       6e+05\nview           5.359e+04   2358.736     22.718      0.000     4.9e+04    5.82e+04\ncondition      1.367e+04   1357.528     10.070      0.000     1.1e+04    1.63e+04\ngrade          9.512e+04   2371.099     40.116      0.000    9.05e+04    9.98e+04\nsqft_above       69.9982      2.486     28.162      0.000      65.126      74.870\nsqft_basement    38.8995      2.938     13.238      0.000      33.140      44.659\nyr_built      -2642.7084     80.986    -32.632      0.000   -2801.449   -2483.968\nyr_renovated     21.4308      4.071      5.264      0.000      13.451      29.411\nzipcode        -548.1478     36.460    -15.034      0.000    -619.614    -476.682\nlat            5.969e+05   1.19e+04     50.305      0.000    5.74e+05     6.2e+05\nlong          -1.944e+05   1.46e+04    -13.312      0.000   -2.23e+05   -1.66e+05\nsqft_living15    20.9021      3.809      5.488      0.000      13.436      28.368\nsqft_lot15       -0.3246      0.082     -3.968      0.000      -0.485      -0.164\n==============================================================================\nOmnibus:                    14975.304   Durbin-Watson:                   1.994\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          1712544.182\nSkew:                           3.632   Prob(JB):                         0.00\nKurtosis:                      51.212   Cond. No.                     9.57e+16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 1.91e-20. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.699</td>  \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.699</td>  \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2363.</td>  \n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 10 Mar 2025</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n</tr>\n<tr>\n  <th>Time:</th>                 <td>17:14:38</td>     <th>  Log-Likelihood:    </th> <td>-2.3542e+05</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td> 17290</td>      <th>  AIC:               </th>  <td>4.709e+05</td> \n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td> 17272</td>      <th>  BIC:               </th>  <td>4.710e+05</td> \n</tr>\n<tr>\n  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>      <td> </td>     \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>         <td> 6.219e+06</td> <td> 3.24e+06</td> <td>    1.917</td> <td> 0.055</td> <td> -1.4e+05</td> <td> 1.26e+07</td>\n</tr>\n<tr>\n  <th>bedrooms</th>      <td>-3.421e+04</td> <td> 2082.322</td> <td>  -16.428</td> <td> 0.000</td> <td>-3.83e+04</td> <td>-3.01e+04</td>\n</tr>\n<tr>\n  <th>bathrooms</th>     <td> 4.439e+04</td> <td> 3607.091</td> <td>   12.306</td> <td> 0.000</td> <td> 3.73e+04</td> <td> 5.15e+04</td>\n</tr>\n<tr>\n  <th>sqft_living</th>   <td>  108.9036</td> <td>    2.530</td> <td>   43.042</td> <td> 0.000</td> <td>  103.944</td> <td>  113.863</td>\n</tr>\n<tr>\n  <th>sqft_lot</th>      <td>    0.0835</td> <td>    0.058</td> <td>    1.445</td> <td> 0.148</td> <td>   -0.030</td> <td>    0.197</td>\n</tr>\n<tr>\n  <th>floors</th>        <td> 7148.8493</td> <td> 3958.506</td> <td>    1.806</td> <td> 0.071</td> <td> -610.224</td> <td> 1.49e+04</td>\n</tr>\n<tr>\n  <th>waterfront</th>    <td> 5.615e+05</td> <td> 1.95e+04</td> <td>   28.786</td> <td> 0.000</td> <td> 5.23e+05</td> <td>    6e+05</td>\n</tr>\n<tr>\n  <th>view</th>          <td> 5.359e+04</td> <td> 2358.736</td> <td>   22.718</td> <td> 0.000</td> <td>  4.9e+04</td> <td> 5.82e+04</td>\n</tr>\n<tr>\n  <th>condition</th>     <td> 1.367e+04</td> <td> 1357.528</td> <td>   10.070</td> <td> 0.000</td> <td>  1.1e+04</td> <td> 1.63e+04</td>\n</tr>\n<tr>\n  <th>grade</th>         <td> 9.512e+04</td> <td> 2371.099</td> <td>   40.116</td> <td> 0.000</td> <td> 9.05e+04</td> <td> 9.98e+04</td>\n</tr>\n<tr>\n  <th>sqft_above</th>    <td>   69.9982</td> <td>    2.486</td> <td>   28.162</td> <td> 0.000</td> <td>   65.126</td> <td>   74.870</td>\n</tr>\n<tr>\n  <th>sqft_basement</th> <td>   38.8995</td> <td>    2.938</td> <td>   13.238</td> <td> 0.000</td> <td>   33.140</td> <td>   44.659</td>\n</tr>\n<tr>\n  <th>yr_built</th>      <td>-2642.7084</td> <td>   80.986</td> <td>  -32.632</td> <td> 0.000</td> <td>-2801.449</td> <td>-2483.968</td>\n</tr>\n<tr>\n  <th>yr_renovated</th>  <td>   21.4308</td> <td>    4.071</td> <td>    5.264</td> <td> 0.000</td> <td>   13.451</td> <td>   29.411</td>\n</tr>\n<tr>\n  <th>zipcode</th>       <td> -548.1478</td> <td>   36.460</td> <td>  -15.034</td> <td> 0.000</td> <td> -619.614</td> <td> -476.682</td>\n</tr>\n<tr>\n  <th>lat</th>           <td> 5.969e+05</td> <td> 1.19e+04</td> <td>   50.305</td> <td> 0.000</td> <td> 5.74e+05</td> <td>  6.2e+05</td>\n</tr>\n<tr>\n  <th>long</th>          <td>-1.944e+05</td> <td> 1.46e+04</td> <td>  -13.312</td> <td> 0.000</td> <td>-2.23e+05</td> <td>-1.66e+05</td>\n</tr>\n<tr>\n  <th>sqft_living15</th> <td>   20.9021</td> <td>    3.809</td> <td>    5.488</td> <td> 0.000</td> <td>   13.436</td> <td>   28.368</td>\n</tr>\n<tr>\n  <th>sqft_lot15</th>    <td>   -0.3246</td> <td>    0.082</td> <td>   -3.968</td> <td> 0.000</td> <td>   -0.485</td> <td>   -0.164</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>14975.304</td> <th>  Durbin-Watson:     </th>  <td>   1.994</td>  \n</tr>\n<tr>\n  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1712544.182</td>\n</tr>\n<tr>\n  <th>Skew:</th>           <td> 3.632</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n</tr>\n<tr>\n  <th>Kurtosis:</th>       <td>51.212</td>   <th>  Cond. No.          </th>  <td>9.57e+16</td>  \n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.91e-20. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular.","text/latex":"\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &      price       & \\textbf{  R-squared:         } &      0.699   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.699   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      2363.   \\\\\n\\textbf{Date:}             & Mon, 10 Mar 2025 & \\textbf{  Prob (F-statistic):} &      0.00    \\\\\n\\textbf{Time:}             &     17:14:38     & \\textbf{  Log-Likelihood:    } & -2.3542e+05  \\\\\n\\textbf{No. Observations:} &       17290      & \\textbf{  AIC:               } &  4.709e+05   \\\\\n\\textbf{Df Residuals:}     &       17272      & \\textbf{  BIC:               } &  4.710e+05   \\\\\n\\textbf{Df Model:}         &          17      & \\textbf{                     } &              \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &              \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                        & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}          &    6.219e+06  &     3.24e+06     &     1.917  &         0.055        &     -1.4e+05    &     1.26e+07     \\\\\n\\textbf{bedrooms}       &   -3.421e+04  &     2082.322     &   -16.428  &         0.000        &    -3.83e+04    &    -3.01e+04     \\\\\n\\textbf{bathrooms}      &    4.439e+04  &     3607.091     &    12.306  &         0.000        &     3.73e+04    &     5.15e+04     \\\\\n\\textbf{sqft\\_living}   &     108.9036  &        2.530     &    43.042  &         0.000        &      103.944    &      113.863     \\\\\n\\textbf{sqft\\_lot}      &       0.0835  &        0.058     &     1.445  &         0.148        &       -0.030    &        0.197     \\\\\n\\textbf{floors}         &    7148.8493  &     3958.506     &     1.806  &         0.071        &     -610.224    &     1.49e+04     \\\\\n\\textbf{waterfront}     &    5.615e+05  &     1.95e+04     &    28.786  &         0.000        &     5.23e+05    &        6e+05     \\\\\n\\textbf{view}           &    5.359e+04  &     2358.736     &    22.718  &         0.000        &      4.9e+04    &     5.82e+04     \\\\\n\\textbf{condition}      &    1.367e+04  &     1357.528     &    10.070  &         0.000        &      1.1e+04    &     1.63e+04     \\\\\n\\textbf{grade}          &    9.512e+04  &     2371.099     &    40.116  &         0.000        &     9.05e+04    &     9.98e+04     \\\\\n\\textbf{sqft\\_above}    &      69.9982  &        2.486     &    28.162  &         0.000        &       65.126    &       74.870     \\\\\n\\textbf{sqft\\_basement} &      38.8995  &        2.938     &    13.238  &         0.000        &       33.140    &       44.659     \\\\\n\\textbf{yr\\_built}      &   -2642.7084  &       80.986     &   -32.632  &         0.000        &    -2801.449    &    -2483.968     \\\\\n\\textbf{yr\\_renovated}  &      21.4308  &        4.071     &     5.264  &         0.000        &       13.451    &       29.411     \\\\\n\\textbf{zipcode}        &    -548.1478  &       36.460     &   -15.034  &         0.000        &     -619.614    &     -476.682     \\\\\n\\textbf{lat}            &    5.969e+05  &     1.19e+04     &    50.305  &         0.000        &     5.74e+05    &      6.2e+05     \\\\\n\\textbf{long}           &   -1.944e+05  &     1.46e+04     &   -13.312  &         0.000        &    -2.23e+05    &    -1.66e+05     \\\\\n\\textbf{sqft\\_living15} &      20.9021  &        3.809     &     5.488  &         0.000        &       13.436    &       28.368     \\\\\n\\textbf{sqft\\_lot15}    &      -0.3246  &        0.082     &    -3.968  &         0.000        &       -0.485    &       -0.164     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 14975.304 & \\textbf{  Durbin-Watson:     } &      1.994   \\\\\n\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 1712544.182  \\\\\n\\textbf{Skew:}          &    3.632  & \\textbf{  Prob(JB):          } &       0.00   \\\\\n\\textbf{Kurtosis:}      &   51.212  & \\textbf{  Cond. No.          } &   9.57e+16   \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The smallest eigenvalue is 1.91e-20. This might indicate that there are \\newline\n strong multicollinearity problems or that the design matrix is singular."},"metadata":{}}],"execution_count":55},{"cell_type":"markdown","source":"**Backward Elimination**","metadata":{}},{"cell_type":"code","source":"# Backward Elimination: Start with all features and remove least significant one by one\n\ndef backward_elimination(X, y, significance_level=0.05):\n    \"\"\" Performs backward elimination based on p-values \"\"\"\n    X = sm.add_constant(X)  # Add constant for intercept\n    model = sm.OLS(y, X).fit()\n    \n    while True:\n        p_values = model.pvalues\n        max_p_value = p_values.max()  # Find max p-value\n        if max_p_value > significance_level:  # If above threshold, remove feature\n            worst_feature = p_values.idxmax()\n            X = X.drop(columns=[worst_feature])\n            model = sm.OLS(y, X).fit()\n        else:\n            break\n            \n    return model, X.columns\n\n# Apply backward elimination\nmodel_backward, selected_features_backward = backward_elimination(X_train, y_train)\n\n# Store results\nmodel_results[\"Backward Elimination\"] = model_backward\n\n# Display selected features\nselected_features_backward\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:14:38.976202Z","iopub.execute_input":"2025-03-10T17:14:38.976585Z","iopub.status.idle":"2025-03-10T17:14:39.036392Z","shell.execute_reply.started":"2025-03-10T17:14:38.976548Z","shell.execute_reply":"2025-03-10T17:14:39.035171Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"Index(['bedrooms', 'bathrooms', 'sqft_living', 'waterfront', 'view',\n       'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built',\n       'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15',\n       'sqft_lot15'],\n      dtype='object')"},"metadata":{}}],"execution_count":56},{"cell_type":"markdown","source":"**Backward Elimination Results:**\nThe following features were retained:\nbedrooms, bathrooms, sqft_living, waterfront, view, condition, grade, sqft_above, sqft_basement, yr_built, yr_renovated, zipcode, lat, long, sqft_living15, sqft_lot15\nsqft_lot and floors were removed due to high p-values.","metadata":{}},{"cell_type":"markdown","source":"**Forward Selection**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\ndef forward_selection(X, y, significance_level=0.05):\n    \"\"\" Performs forward selection based on p-values \"\"\"\n    selected_features = []\n    remaining_features = list(X.columns)\n    X_const = sm.add_constant(X)  # Add constant for intercept\n    best_model = None\n\n    while remaining_features:\n        best_p_value = float('inf')\n        best_feature = None\n        temp_model = None\n\n        for feature in remaining_features:\n            temp_features = selected_features + [feature]\n            temp_X = X_const[temp_features + ['const']]\n            model = sm.OLS(y, temp_X).fit()\n            p_value = model.pvalues[feature]\n\n            if p_value < significance_level and p_value < best_p_value:\n                best_p_value = p_value\n                best_feature = feature\n                temp_model = model\n\n        if best_feature is not None:\n            selected_features.append(best_feature)\n            remaining_features.remove(best_feature)\n            best_model = temp_model\n        else:\n            break\n\n    return best_model, selected_features\n\n# Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Apply forward selection\nmodel_forward, selected_features_forward = forward_selection(X_train, y_train)\n\n# Display selected features\nprint(\"Selected Features:\", selected_features_forward)\nprint(model_forward.summary())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:14:39.037415Z","iopub.execute_input":"2025-03-10T17:14:39.037736Z","iopub.status.idle":"2025-03-10T17:14:39.884081Z","shell.execute_reply.started":"2025-03-10T17:14:39.037710Z","shell.execute_reply":"2025-03-10T17:14:39.883006Z"}},"outputs":[{"name":"stdout","text":"Selected Features: ['bedrooms', 'bathrooms', 'sqft_living', 'yr_built', 'grade', 'lat', 'waterfront', 'view', 'zipcode', 'long', 'condition', 'sqft_above', 'sqft_basement', 'yr_renovated', 'sqft_living15', 'sqft_lot15']\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                  price   R-squared:                       0.699\nModel:                            OLS   Adj. R-squared:                  0.699\nMethod:                 Least Squares   F-statistic:                     2677.\nDate:                Mon, 10 Mar 2025   Prob (F-statistic):               0.00\nTime:                        17:14:39   Log-Likelihood:            -2.3542e+05\nNo. Observations:               17290   AIC:                         4.709e+05\nDf Residuals:                   17274   BIC:                         4.710e+05\nDf Model:                          15                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nbedrooms      -3.439e+04   2081.029    -16.524      0.000   -3.85e+04   -3.03e+04\nbathrooms      4.612e+04   3476.868     13.265      0.000    3.93e+04    5.29e+04\nsqft_living     108.5643      2.509     43.267      0.000     103.646     113.482\nyr_built      -2615.9006     78.890    -33.159      0.000   -2770.533   -2461.268\ngrade          9.555e+04   2361.973     40.455      0.000    9.09e+04       1e+05\nlat            5.983e+05   1.18e+04     50.644      0.000    5.75e+05    6.21e+05\nwaterfront     5.614e+05   1.95e+04     28.777      0.000    5.23e+05       6e+05\nview           5.376e+04   2357.718     22.801      0.000    4.91e+04    5.84e+04\nzipcode        -541.8867     36.310    -14.924      0.000    -613.057    -470.716\nlong          -1.951e+05   1.45e+04    -13.464      0.000   -2.23e+05   -1.67e+05\ncondition      1.351e+04   1355.135      9.968      0.000    1.09e+04    1.62e+04\nsqft_above       71.8046      2.309     31.091      0.000      67.278      76.331\nsqft_basement    36.7596      2.679     13.723      0.000      31.509      42.010\nyr_renovated     21.7787      4.065      5.357      0.000      13.810      29.747\nsqft_living15    19.8247      3.779      5.246      0.000      12.418      27.232\nsqft_lot15       -0.2476      0.058     -4.285      0.000      -0.361      -0.134\nconst          5.401e+06   3.19e+06      1.693      0.090   -8.51e+05    1.17e+07\n==============================================================================\nOmnibus:                    14923.327   Durbin-Watson:                   1.993\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          1687773.885\nSkew:                           3.614   Prob(JB):                         0.00\nKurtosis:                      50.859   Cond. No.                     3.44e+17\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 1.43e-21. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"markdown","source":"**Forward Selection Results:**\nThe following features were selected:\nbedrooms, bathrooms, sqft_living, yr_built, grade, lat, waterfront, view, zipcode, long, condition, sqft_above, sqft_basement, yr_renovated, sqft_living15, sqft_lot15\nsqft_lot and floors were not selected, similar to Backward Elimination.","metadata":{}},{"cell_type":"markdown","source":"**Stepwise Selection**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\ndef stepwise_selection(X, y, significance_level=0.05):\n    \"\"\" Performs stepwise selection (both forward and backward) \"\"\"\n    selected_features = []\n    remaining_features = list(X.columns)\n    X_const = sm.add_constant(X)  # Add constant for intercept\n\n    while remaining_features:\n        best_p_value = float('inf')\n        best_feature = None\n\n        # Forward Step: Find best feature to add\n        for feature in remaining_features:\n            temp_features = selected_features + [feature]\n            temp_X = X_const[temp_features + ['const']]\n            model = sm.OLS(y, temp_X).fit()\n            p_value = model.pvalues[feature]\n\n            if p_value < significance_level and p_value < best_p_value:\n                best_p_value = p_value\n                best_feature = feature\n\n        if best_feature is not None:\n            selected_features.append(best_feature)\n            remaining_features.remove(best_feature)\n\n        # Backward Step: Remove worst feature if necessary\n        temp_X = X_const[selected_features + ['const']]\n        model = sm.OLS(y, temp_X).fit()\n        p_values = model.pvalues.drop('const')  # Exclude intercept\n        worst_p_value = p_values.max()\n\n        if worst_p_value > significance_level:\n            worst_feature = p_values.idxmax()\n            selected_features.remove(worst_feature)\n\n        if best_feature is None and worst_p_value <= significance_level:\n            break\n\n    return model, selected_features\n\n\n# Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Apply stepwise selection\nmodel_stepwise, selected_features_stepwise = stepwise_selection(X_train, y_train)\n\n# Display selected features\nprint(\"Selected Features:\", selected_features_stepwise)\nprint(model_stepwise.summary())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:14:39.884973Z","iopub.execute_input":"2025-03-10T17:14:39.885233Z","iopub.status.idle":"2025-03-10T17:14:40.876237Z","shell.execute_reply.started":"2025-03-10T17:14:39.885211Z","shell.execute_reply":"2025-03-10T17:14:40.875005Z"}},"outputs":[{"name":"stdout","text":"Selected Features: ['bedrooms', 'bathrooms', 'sqft_living', 'yr_built', 'grade', 'lat', 'waterfront', 'view', 'zipcode', 'long', 'condition', 'sqft_above', 'sqft_basement', 'yr_renovated', 'sqft_living15', 'sqft_lot15']\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                  price   R-squared:                       0.699\nModel:                            OLS   Adj. R-squared:                  0.699\nMethod:                 Least Squares   F-statistic:                     2677.\nDate:                Mon, 10 Mar 2025   Prob (F-statistic):               0.00\nTime:                        17:14:40   Log-Likelihood:            -2.3542e+05\nNo. Observations:               17290   AIC:                         4.709e+05\nDf Residuals:                   17274   BIC:                         4.710e+05\nDf Model:                          15                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nbedrooms      -3.439e+04   2081.029    -16.524      0.000   -3.85e+04   -3.03e+04\nbathrooms      4.612e+04   3476.868     13.265      0.000    3.93e+04    5.29e+04\nsqft_living     108.5643      2.509     43.267      0.000     103.646     113.482\nyr_built      -2615.9006     78.890    -33.159      0.000   -2770.533   -2461.268\ngrade          9.555e+04   2361.973     40.455      0.000    9.09e+04       1e+05\nlat            5.983e+05   1.18e+04     50.644      0.000    5.75e+05    6.21e+05\nwaterfront     5.614e+05   1.95e+04     28.777      0.000    5.23e+05       6e+05\nview           5.376e+04   2357.718     22.801      0.000    4.91e+04    5.84e+04\nzipcode        -541.8867     36.310    -14.924      0.000    -613.057    -470.716\nlong          -1.951e+05   1.45e+04    -13.464      0.000   -2.23e+05   -1.67e+05\ncondition      1.351e+04   1355.135      9.968      0.000    1.09e+04    1.62e+04\nsqft_above       71.8046      2.309     31.091      0.000      67.278      76.331\nsqft_basement    36.7596      2.679     13.723      0.000      31.509      42.010\nyr_renovated     21.7787      4.065      5.357      0.000      13.810      29.747\nsqft_living15    19.8247      3.779      5.246      0.000      12.418      27.232\nsqft_lot15       -0.2476      0.058     -4.285      0.000      -0.361      -0.134\nconst          5.401e+06   3.19e+06      1.693      0.090   -8.51e+05    1.17e+07\n==============================================================================\nOmnibus:                    14923.327   Durbin-Watson:                   1.993\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          1687773.885\nSkew:                           3.614   Prob(JB):                         0.00\nKurtosis:                      50.859   Cond. No.                     3.44e+17\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 1.43e-21. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n","output_type":"stream"}],"execution_count":58}]}