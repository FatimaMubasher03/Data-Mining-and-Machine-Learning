{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6482469,"sourceType":"datasetVersion","datasetId":3745370}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:09:15.842673Z","iopub.execute_input":"2025-03-10T18:09:15.843093Z","iopub.status.idle":"2025-03-10T18:09:15.850927Z","shell.execute_reply.started":"2025-03-10T18:09:15.843017Z","shell.execute_reply":"2025-03-10T18:09:15.849688Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/fish-market/Fish.csv\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Load the dataset\nfile_path = \"/kaggle/input/fish-market/Fish.csv\"\ndf = pd.read_csv(file_path)\n\n# Display basic info to confirm successful loading\ndf.info(), df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:09:15.853568Z","iopub.execute_input":"2025-03-10T18:09:15.853943Z","iopub.status.idle":"2025-03-10T18:09:15.885948Z","shell.execute_reply.started":"2025-03-10T18:09:15.853914Z","shell.execute_reply":"2025-03-10T18:09:15.885012Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159 entries, 0 to 158\nData columns (total 7 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Species  159 non-null    object \n 1   Weight   159 non-null    float64\n 2   Length1  159 non-null    float64\n 3   Length2  159 non-null    float64\n 4   Length3  159 non-null    float64\n 5   Height   159 non-null    float64\n 6   Width    159 non-null    float64\ndtypes: float64(6), object(1)\nmemory usage: 8.8+ KB\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(None,\n   Species  Weight  Length1  Length2  Length3   Height   Width\n 0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n 1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n 2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n 3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n 4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nimport statsmodels.api as sm\nimport numpy as np\n\n# Define independent and dependent variables\nX = df[['Length1', 'Length2', 'Length3', 'Height', 'Width']]\ny = df['Weight']\n\n# Transform features into polynomial terms (degree=2 for this analysis)\npoly = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly.fit_transform(X)\n\n# Keep track of model performance\nresults = {}\n\n# Helper function to calculate adjusted RÂ²\ndef adjusted_r2(r2, n, k):\n    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n\n# 1. Keep All Variables (Full Model)\nlin_reg = LinearRegression()\nlin_reg.fit(X_poly, y)\ny_pred = lin_reg.predict(X_poly)\nr2_full = r2_score(y, y_pred)\nadj_r2_full = adjusted_r2(r2_full, len(y), X_poly.shape[1])\nresults['Keep All Variables'] = (r2_full, adj_r2_full)\n\n# 2. Backward Elimination\nX_poly_with_const = sm.add_constant(X_poly)\nmodel = sm.OLS(y, X_poly_with_const).fit()\np_values = model.pvalues[1:]  # Exclude intercept\nselected_features = np.where(p_values < 0.05)[0]\n\nX_selected = X_poly[:, selected_features]  # Keep only significant features\nlin_reg.fit(X_selected, y)\ny_pred = lin_reg.predict(X_selected)\nr2_backward = r2_score(y, y_pred)\nadj_r2_backward = adjusted_r2(r2_backward, len(y), X_selected.shape[1])\nresults['Backward Elimination'] = (r2_backward, adj_r2_backward)\n\n# 3. Forward Selection\nremaining_features = []\nbest_r2 = -np.inf\n\nfor i in range(X_poly.shape[1]):\n    temp_features = remaining_features + [i]\n    X_temp = X_poly[:, temp_features]\n    lin_reg.fit(X_temp, y)\n    y_pred = lin_reg.predict(X_temp)\n    r2_temp = r2_score(y, y_pred)\n    \n    if r2_temp > best_r2:\n        best_r2 = r2_temp\n        remaining_features.append(i)\n\nX_forward = X_poly[:, remaining_features]\nlin_reg.fit(X_forward, y)\ny_pred = lin_reg.predict(X_forward)\nr2_forward = r2_score(y, y_pred)\nadj_r2_forward = adjusted_r2(r2_forward, len(y), X_forward.shape[1])\nresults['Forward Selection'] = (r2_forward, adj_r2_forward)\n\n# 4. Bidirectional Selection (Combining Forward & Backward)\nselected_features = []\nbest_r2 = -np.inf\n\nfor _ in range(X_poly.shape[1]):\n    # Forward Step\n    remaining_features = [i for i in range(X_poly.shape[1]) if i not in selected_features]\n    best_feature = None\n    \n    for feature in remaining_features:\n        temp_features = selected_features + [feature]\n        X_temp = X_poly[:, temp_features]\n        lin_reg.fit(X_temp, y)\n        y_pred = lin_reg.predict(X_temp)\n        r2_temp = r2_score(y, y_pred)\n        \n        if r2_temp > best_r2:\n            best_r2 = r2_temp\n            best_feature = feature\n\n    if best_feature is not None:\n        selected_features.append(best_feature)\n\n    # Backward Step\n    X_temp = X_poly[:, selected_features]\n    lin_reg.fit(X_temp, y)\n    model = sm.OLS(y, sm.add_constant(X_temp)).fit()\n    p_values = model.pvalues[1:]\n\n    for i, p_val in enumerate(p_values):\n        if p_val > 0.05:\n            selected_features.pop(i)\n\nX_bidirectional = X_poly[:, selected_features]\nlin_reg.fit(X_bidirectional, y)\ny_pred = lin_reg.predict(X_bidirectional)\nr2_bidirectional = r2_score(y, y_pred)\nadj_r2_bidirectional = adjusted_r2(r2_bidirectional, len(y), X_bidirectional.shape[1])\nresults['Bidirectional Selection'] = (r2_bidirectional, adj_r2_bidirectional)\n\n# Show results\nresults\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:09:15.887192Z","iopub.execute_input":"2025-03-10T18:09:15.887524Z","iopub.status.idle":"2025-03-10T18:09:16.574691Z","shell.execute_reply.started":"2025-03-10T18:09:15.887497Z","shell.execute_reply":"2025-03-10T18:09:16.573675Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'Keep All Variables': (0.9832188512811139, 0.9807868007421449),\n 'Backward Elimination': (0.8256300958984538, 0.8233945843074084),\n 'Forward Selection': (0.9832188512811129, 0.9807868007421437),\n 'Bidirectional Selection': (0.9722423295067167, 0.9717050842713628)}"},"metadata":{}}],"execution_count":16}]}